{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9080dd2e-9bb1-433a-9891-3fb22104b709",
   "metadata": {},
   "source": [
    "# Module 02: Experiment Tracking\n",
    "\n",
    "The purpose of this notebook is to follow the second module and its videos:\n",
    "- Getting started with MLflow\n",
    "- Experiment tracking with MLflow\n",
    "- Model Management\n",
    "\n",
    "The base for this notebook is the one from the Module 01: Introduction homework, and its video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270a8993-1a81-4237-8b2f-c579c62f8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for preparing and training data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8f2b34-8ac9-4c74-8b22-0ce78b7689c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLFlow for experiment tracking\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "# Import pickle to save the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6742afb4-f6f4-4cf0-bc31-f58f618d7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import xgb and hyperopt\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da491f23-e43c-4143-a081-1add073aa324",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2585010344.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    outliers_indices = np.where((df[\"duration\"] < 1) | (df[] > 60))\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Create a function to prepare taxi data\n",
    "def prepare_taxi_data(file):\n",
    "    \n",
    "    # Read the parquet file\n",
    "    df = pd.read_parquet(file)\n",
    "\n",
    "    # Create duration column\n",
    "    df[\"duration\"] = df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]\n",
    "    df[\"duration\"] = pd.to_timedelta(df[\"duration\"])/pd.Timedelta('60s')\n",
    "\n",
    "    # Remove outliers\n",
    "    outliers_indices = np.where((df[\"duration\"] < 1) | (df[\"duration\"] > 60))\n",
    "    df = df.drop(outliers_indices[0])\n",
    "\n",
    "    # Change categorical columns to string to not generate conflicts later when\n",
    "    # creating the features matrix\n",
    "    categorical=['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb149e4-dc5f-4331-b33d-fb701ae7bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "training_df = prepare_taxi_data('../../../data/yellow_tripdata_2023-01.parquet')\n",
    "\n",
    "# Prepare validation data\n",
    "validate_df = prepare_taxi_data('../../../data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a60559-11f1-44a5-a6ec-b835508bfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode and get features matrix\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Learn mappings from dict and transform to matrix\n",
    "train_dicts = training_df[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Learn mappings from dict and transform to matrix\n",
    "val_dicts = validate_df[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5acb24f5-6493-4b3c-a1be-85c29dd842d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target values to train the model\n",
    "y_train = training_df['duration'].values\n",
    "y_val = validate_df['duration'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac85c0ed-ce90-4cb9-b93a-46fed5c08a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option number one to save models\n",
    "\n",
    "# Start a new MLfLow run, train the Lasso model and save it\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log tags and params\n",
    "    mlflow.set_tag('developer', 'eduga')\n",
    "    mlflow.set_tag('model', 'lasso')\n",
    "    mlflow.log_param('train_data_path', '../../../data/yellow_tripdata_2023-01.parquet')\n",
    "    mlflow.log_param('validate_data_path', '../../../data/yellow_tripdata_2023-02.parquet')\n",
    "    \n",
    "    alpha = 0.01\n",
    "    mlflow.log_param('alpha', alpha)\n",
    "\n",
    "    # Train the model and predict\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    # Get the error and log it\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "\n",
    "    # Save the preprocessor\n",
    "    with open('models/preprocessor.b', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\n",
    "        'models/preprocessor.b',\n",
    "        artifact_path='preprocessor'\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        lr,\n",
    "        artifact_path='models_mlflow'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec4cc682-4f5e-4305-9819-4be97af8cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:8.08909\n",
      "[1]\tvalidation-rmse:6.36828\n",
      "[2]\tvalidation-rmse:6.11740\n",
      "[3]\tvalidation-rmse:5.85362\n",
      "[4]\tvalidation-rmse:5.80118\n",
      "[5]\tvalidation-rmse:5.55971\n",
      "[6]\tvalidation-rmse:5.45833\n",
      "[7]\tvalidation-rmse:5.42895\n",
      "[8]\tvalidation-rmse:5.38311\n",
      "[9]\tvalidation-rmse:5.33248\n",
      "[10]\tvalidation-rmse:5.29358\n",
      "[11]\tvalidation-rmse:5.28172\n",
      "[12]\tvalidation-rmse:5.27465\n",
      "[13]\tvalidation-rmse:5.26293\n",
      "[14]\tvalidation-rmse:5.23730\n",
      "[15]\tvalidation-rmse:5.23484\n",
      "[16]\tvalidation-rmse:5.23284\n",
      "[17]\tvalidation-rmse:5.22938\n",
      "[18]\tvalidation-rmse:5.22391\n",
      "[19]\tvalidation-rmse:5.22091\n",
      "[20]\tvalidation-rmse:5.21904\n",
      "[21]\tvalidation-rmse:5.21889\n",
      "[22]\tvalidation-rmse:5.21787\n",
      "[23]\tvalidation-rmse:5.21678\n",
      "[24]\tvalidation-rmse:5.21479\n",
      "[25]\tvalidation-rmse:5.21395\n",
      "[26]\tvalidation-rmse:5.21387\n",
      "[27]\tvalidation-rmse:5.21391\n",
      "[28]\tvalidation-rmse:5.21365\n",
      "[29]\tvalidation-rmse:5.21339\n",
      "[30]\tvalidation-rmse:5.21337\n",
      "[31]\tvalidation-rmse:5.21336\n",
      "[32]\tvalidation-rmse:5.21324\n",
      "[33]\tvalidation-rmse:5.21324\n",
      "[34]\tvalidation-rmse:5.21320\n",
      "[35]\tvalidation-rmse:5.21322\n",
      "[36]\tvalidation-rmse:5.21316\n",
      "[37]\tvalidation-rmse:5.21324\n",
      "[38]\tvalidation-rmse:5.21316\n",
      "[39]\tvalidation-rmse:5.21320\n",
      "[40]\tvalidation-rmse:5.21326\n",
      "[41]\tvalidation-rmse:5.21328\n",
      "[42]\tvalidation-rmse:5.21329\n",
      "[43]\tvalidation-rmse:5.21332\n",
      "[44]\tvalidation-rmse:5.21335\n",
      "[45]\tvalidation-rmse:5.21339\n",
      "[46]\tvalidation-rmse:5.21341\n",
      "[47]\tvalidation-rmse:5.21342\n",
      "[48]\tvalidation-rmse:5.21343\n",
      "[49]\tvalidation-rmse:5.21345\n",
      "[50]\tvalidation-rmse:5.21345\n",
      "[51]\tvalidation-rmse:5.21345\n",
      "[52]\tvalidation-rmse:5.21346\n",
      "[53]\tvalidation-rmse:5.21347\n",
      "[54]\tvalidation-rmse:5.21347\n",
      "[55]\tvalidation-rmse:5.21348\n",
      "[56]\tvalidation-rmse:5.21348\n",
      "[57]\tvalidation-rmse:5.21349\n",
      "[58]\tvalidation-rmse:5.21349\n",
      "[59]\tvalidation-rmse:5.21350\n",
      "[60]\tvalidation-rmse:5.21350\n",
      "[61]\tvalidation-rmse:5.21350\n",
      "[62]\tvalidation-rmse:5.21350\n",
      "[63]\tvalidation-rmse:5.21351\n",
      "[64]\tvalidation-rmse:5.21351\n",
      "[65]\tvalidation-rmse:5.21351\n",
      "[66]\tvalidation-rmse:5.21351\n",
      "[67]\tvalidation-rmse:5.21351\n",
      "[68]\tvalidation-rmse:5.21351\n",
      "[69]\tvalidation-rmse:5.21352\n",
      "[70]\tvalidation-rmse:5.21352\n",
      "[71]\tvalidation-rmse:5.21352\n",
      "[72]\tvalidation-rmse:5.21352\n",
      "[73]\tvalidation-rmse:5.21352\n",
      "[74]\tvalidation-rmse:5.21352\n",
      "[75]\tvalidation-rmse:5.21353\n",
      "[76]\tvalidation-rmse:5.21353\n",
      "[77]\tvalidation-rmse:5.21352\n",
      "[78]\tvalidation-rmse:5.21352\n",
      "[79]\tvalidation-rmse:5.21353\n",
      "[80]\tvalidation-rmse:5.21353\n",
      "[81]\tvalidation-rmse:5.21353\n",
      "[82]\tvalidation-rmse:5.21353\n",
      "[83]\tvalidation-rmse:5.21353\n",
      "[84]\tvalidation-rmse:5.21353\n",
      "[85]\tvalidation-rmse:5.21353\n",
      "[86]\tvalidation-rmse:5.21353\n",
      "[87]\tvalidation-rmse:5.21353\n",
      "[88]\tvalidation-rmse:5.21353\n"
     ]
    }
   ],
   "source": [
    "# Option number two to save models\n",
    "\n",
    "# Model the best xgb run from mlflow, performance and optimization wise\n",
    "best_params = {\n",
    "    'learning_rate': 0.7720684014557972,\n",
    "    'max_depth': 58,\n",
    "    'min_child_weight': 0.6989693091372148,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'reg_alpha': 0.015100098245236579,\n",
    "    'reg_lambda': 0.03214589450610109,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log tags and params\n",
    "    mlflow.set_tag('model', 'xgboost')\n",
    "    mlflow.set_tag('developer', 'eduga')\n",
    "    mlflow.log_param('train_data_path', '../../../data/yellow_tripdata_2023-01.parquet')\n",
    "    mlflow.log_param('validate_data_path', '../../../data/yellow_tripdata_2023-02.parquet')\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Train the model and predict\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=250,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    y_pred = booster.predict(valid)\n",
    "\n",
    "    # Get the error and log it\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Save and log preprocessor\n",
    "    with open('models/preprocessor.b', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\n",
    "        'models/preprocessor.b',\n",
    "        artifact_path='preprocessor'\n",
    "    )\n",
    "        \n",
    "    # Use xgboost.log_model method to save the model\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster,\n",
    "        artifact_path='models_mlflow'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c680818-c0a7-4754-9985-10839a8c2f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.290758, 44.159   , 15.870378, 21.573727, 25.2379  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In MLflow, when inspecting a run's artifacts, the run's URI can be extracted. With it,\n",
    "# a new xgb booster object can be made. This can also be a python function, where mlflow\n",
    "# and pandas are the only dependencies to be imported.\n",
    "\n",
    "# URI from MLflow\n",
    "logged_model = 'runs:/cbf3d520b4d44905bd9c8cc155140711/models_mlflow'\n",
    "\n",
    "# Apply the same framework we've been iterating\n",
    "xgboost_model = mlflow.xgboost.load_model(logged_model)\n",
    "y_pred = xgboost_model.predict(valid)\n",
    "y_pred[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
